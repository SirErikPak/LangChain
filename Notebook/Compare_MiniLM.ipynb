{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aadea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders1 = [\n",
    "    PyPDFLoader(\"../Data/botanical.pdf\"),\n",
    "    PyPDFLoader(\"../Data/astronomical.pdf\"),\n",
    "    PyPDFLoader(\"../Data/biological.pdf\"),\n",
    "    PyPDFLoader(\"../Data/cosmological.pdf\"),\n",
    "    PyPDFLoader(\"../Data/culinary.pdf\"),\n",
    "    PyPDFLoader(\"../Data/pharmaceutical.pdf\")\n",
    "]\n",
    "\n",
    "loaders2 = [\n",
    "    PyMuPDFLoader(\"../Data/botanical.pdf\"),\n",
    "    PyMuPDFLoader(\"../Data/astronomical.pdf\"),\n",
    "    PyMuPDFLoader(\"../Data/biological.pdf\"),\n",
    "    PyMuPDFLoader(\"../Data/cosmological.pdf\"),\n",
    "    PyMuPDFLoader(\"../Data/culinary.pdf\"),\n",
    "    PyMuPDFLoader(\"../Data/pharmaceutical.pdf\")\n",
    "]\n",
    "\n",
    "loaders3 = [\n",
    "    PyMuPDF4LLMLoader(\"../Data/botanical.pdf\"),\n",
    "    PyMuPDF4LLMLoader(\"../Data/astronomical.pdf\"),\n",
    "    PyMuPDF4LLMLoader(\"../Data/biological.pdf\"),\n",
    "    PyMuPDF4LLMLoader(\"../Data/cosmological.pdf\"),\n",
    "    PyMuPDF4LLMLoader(\"../Data/culinary.pdf\"),\n",
    "    PyMuPDF4LLMLoader(\"../Data/pharmaceutical.pdf\")\n",
    "]\n",
    "\n",
    "docs_py = []\n",
    "docs_pymu = []\n",
    "docs_py4llm = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd2c38",
   "metadata": {},
   "source": [
    "PyPDFLoader, PyMuPDFLoader, and PyMuPDF4LLMLoader are all LangChain-compatible PDF loaders, but they differ in backend library, document layout handling, and output richness.\n",
    "\n",
    "- PyPDFLoader\n",
    "    - Backend: Uses pypdf/PyPDF2.\n",
    "    - Strengths: Quick, efficient plain-text extraction from simple PDFs.\n",
    "    - Limitations: Struggles with multi-column layouts, tables, images, and complex formatting; may emit warnings for malformed PDFs.\n",
    "    - Use case: Best for basic, well-structured text PDFs.\n",
    "\n",
    "- PyMuPDFLoader\n",
    "    - Backend: Uses PyMuPDF (pymupdf).\n",
    "    - Strengths: Robust parsing from complex layouts—handles multi-column text, some tables, images, and non-standard page formats better.\n",
    "    - Limitations: Output is generally plain text; advanced formatting (markdown, table extraction) is limited.\n",
    "    - Use case: Preferred for scientific papers, forms, and rich-layout documents where PyPDFLoader fails.\n",
    "\n",
    "- PyMuPDF4LLMLoader\n",
    "    - Backend: Advanced usage of PyMuPDF with markdown and LLM-oriented formatting.\n",
    "    - Strengths:\n",
    "        - Extracts well-structured markdown: headings, lists, tables, code blocks.\n",
    "        - Tables converted to markdown, images referenced in output.\n",
    "        - Customizable splitting (by page, flowing text), better for LLM input.\n",
    "        - Superior for RAG or QA pipelines due to markdown fidelity.\n",
    "    - Limitations: Slightly heavier dependency, may require fine-tuning settings for best results.\n",
    "    - Use case: When highest-quality, markdown-structured output is needed for downstream language model or retrieval tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aae90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "for loader in loaders1:\n",
    "    docs = loader.load()\n",
    "    docs_py.extend(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61510f2",
   "metadata": {},
   "source": [
    "- Struggling with multi-column PDF documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9379db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in loaders2:\n",
    "    docs = loader.load()\n",
    "    docs_pymu.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ab0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in loaders3:\n",
    "    docs = loader.load()\n",
    "    docs_py4llm.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2bf238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Botanical Section \\nBotanixum Sectiorum Arcanix \\n \\nA peculiar plant with spiraling leaves and \\nvibrant blue flowers that seem to emit a \\nfaint glow in moonlight. \\n• \\nHoloris spiralis: In lumine lunae, \\nflores azuri magni brillant. \\n• \\nRadices mysticae: Radices intortae \\nterram quaerunt, lumina nocturna \\nsequentes. \\n• \\nUsus: Extractum florae noctem \\nilluminat, mentem serenat. \\n \\nLuminaflora Spiralis \\nLuminaflora Spiralis thrives under the \\nmoon's tender gaze, where its spiraling \\nleaves and vibrant blue petals unfold in a \\nmesmerizing dance of light. Believed by \\nancient scholars to bridge the earthly \\nrealm with the ethereal, these plants \\nradiate a soft luminescence, guiding lost \\ntravelers through the darkest nights. \\nMystics and poets claim that merely \\nbeing in the presence of Luminaflora can \\nsoothe troubled thoughts and illuminate \\nthe path to inner peace.  \\n \\nThe roots of Luminaflora Spiralis are as \\nintriguing as its blooms. Entwining \\ndeeply within the earth, they seek not \\nwater, but moonlight that filters through \\nthe soil, a phenomenon that baffles even \\nthe most learned botanists. The plant's \\naffinity for lunar rays is reflected in its \\ngrowth cycle, with each phase of the \\nmoon bringing about subtle changes in \\nits luminescence and petal orientation. \\nThis unique symbiosis with the moon \\nmakes Luminaflora a subject of endless \\nfascination. \\n \\nIn medicinal practices, extracts from \\nLuminaflora Spiralis are highly valued for \\ntheir illuminating properties. Alchemists \\nconcoct potions that harness the plant's \\nglow, claiming such elixirs can light up \\none's inner darkness, dispelling\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_pymu[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374f2caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# **Botanical Section**\\n\\n### **Botanixum Sectiorum Arcanix**\\n\\n## **Luminaflora Spiralis**\\n\\n\\n\\nA peculiar plant with spiraling leaves and\\n\\nvibrant blue flowers that seem to emit a\\n\\nfaint glow in moonlight.\\n\\n\\n  - **Holoris spiralis:** In lumine lunae,\\nflores azuri magni brillant.\\n\\n\\n  - **Radices mysticae:** Radices intortae\\nterram quaerunt, lumina nocturna\\n\\nsequentes.\\n\\n\\n  - **Usus:** Extractum florae noctem\\n\\nilluminat, mentem serenat.\\n\\n\\n\\n**Luminaflora Spiralis** thrives under the\\nmoon's tender gaze, where its spiraling\\nleaves and vibrant blue petals unfold in a\\nmesmerizing dance of light. Believed by\\nancient scholars to bridge the earthly\\nrealm with the ethereal, these plants\\nradiate a soft luminescence, guiding lost\\ntravelers through the darkest nights.\\nMystics and poets claim that merely\\nbeing in the presence of Luminaflora can\\nsoothe troubled thoughts and illuminate\\nthe path to inner peace.\\n\\nThe roots of Luminaflora Spiralis are as\\nintriguing as its blooms. Entwining\\ndeeply within the earth, they seek not\\nwater, but moonlight that filters through\\nthe soil, a phenomenon that baffles even\\nthe most learned botanists. The plant's\\naffinity for lunar rays is reflected in its\\ngrowth cycle, with each phase of the\\nmoon bringing about subtle changes in\\nits luminescence and petal orientation.\\nThis unique symbiosis with the moon\\nmakes Luminaflora a subject of endless\\nfascination.\\n\\nIn medicinal practices, extracts from\\nLuminaflora Spiralis are highly valued for\\ntheir illuminating properties. Alchemists\\nconcoct potions that harness the plant's\\nglow, claiming such elixirs can light up\\none's inner darkness, dispelling\\n\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_py4llm[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f059b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1621"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_pymu[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acd71d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1632"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_py4llm[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fbbed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_py), len(docs_pymu),len(docs_py4llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b380338",
   "metadata": {},
   "source": [
    "## Split Documents into Chunks\n",
    "\n",
    "The main difference between `CharacterTextSplitter` and `RecursiveCharacterTextSplitter` lies in how they split text into chunks, especially when dealing with preserving logical boundaries in text.\n",
    "- `CharacterTextSplitter`\n",
    "    - Splits text simply by a single specified separator (e.g. newline \\n).\n",
    "    - Splits text into fixed-size chunks with overlap based solely on character count.\n",
    "    - It does not attempt to preserve sentence, paragraph, or semantic structure; splits can be arbitrary.\n",
    "    - Example: split at every newline, group next 1000 characters, overlap 150 characters. It operates in a straightforward, linear way.\n",
    "    - `CharacterTextSplitter` splits text based on a fixed character separator into chunks defined by number of characters, with overlap for context continuity. It’s a simple, character-based chunking method suitable for basic text splitting.\n",
    "\n",
    "- `RecursiveCharacterTextSplitter`\n",
    "    - More sophisticated splitter that tries to preserve semantic boundaries like paragraphs, sentences, or words.\n",
    "    - Splits text recursively using a priority list of separators (default: [\"\\n\\n\", \"\\n\", \" \", \"\"]).\n",
    "    - Starts splitting by the largest separator (double newline), if resulting chunks are still too large, splits those chunks by the next separator (single newline), and so forth, until chunks are under the size limit. This avoids breaking natural text units abruptly by chunking on logical boundaries like paragraphs or sentences. Designed especially for preparing texts for LLMs to keep context coherent. Can keep or discard separators and supports regex-based separators.\n",
    "    - `RecursiveCharacterTextSplitter` recursively splits text on progressively smaller separators (paragraphs, lines, words) to create coherent chunks fitting size constraints, making it ideal for LLM applications requiring semantically meaningful chunks.\n",
    "\n",
    "- `PythonCodeTextSplitter` in LangChain is a specialized text splitter designed to split source code, specifically Python code, into logical chunks based on Python syntax structures.\n",
    "    - Key Characteristics:\n",
    "        - Splitting Logic:\n",
    "        - It attempts to split text along Python-specific syntax boundaries, such as class definitions (class), function/method definitions (def), and other Python code blocks.\n",
    "    - Implementation:\n",
    "        - It is implemented as a subclass of RecursiveCharacterTextSplitter with Python-specific separators tailored for Python code.\n",
    "    - Chunk Size Measurement:\n",
    "        - By default, chunk size is measured by the number of characters, but this can be controlled with custom length functions.\n",
    "    - Use Case:\n",
    "        - Useful when processing Python code for tasks such as code analysis, code search, or feeding code into LLMs, ensuring splits don't cut through syntax elements but align on logical code blocks.\n",
    "    - Example Usage:\n",
    "        ```from langchain.text_splitter import PythonCodeTextSplitter\n",
    "        python_text = \"\"\"\n",
    "        class Foo:\n",
    "             def bar():\n",
    "                 pass\n",
    "             def foo():\n",
    "                 pass\n",
    "        \"\"\"\n",
    "\n",
    "        splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "        docs = splitter.create_documents([python_text])\n",
    "    - Result:\n",
    "        - The text is split into chunks aligned with Python class/method blocks rather than arbitrary character count splits.\n",
    "\n",
    "    - Summary:\n",
    "        - `PythonCodeTextSplitter` is designed to split Python source code into meaningful chunks based on syntax like classes and functions. It preserves code structure during splitting and is ideal for code-related NLP or LLM tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "625e589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "text_splitter_recur = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # List of separators to use for splitting, in order of preference\n",
    "    chunk_size=1_000,                   # Max size of each chunk (measured by characters or tokens)\n",
    "    chunk_overlap=150,                  # Number of characters overlapping between chunks to maintain context continuity\n",
    "    length_function=len,                # Function to measure chunk length (default is Python's len)\n",
    "    is_separator_regex=False,           # Whether separators are interpreted as regex (default False)\n",
    ")\n",
    "\n",
    "text_splitter_char = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1_000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05975a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks using both docs splitters\n",
    "docs_pymu_recursive = text_splitter_recur.split_documents(docs_pymu)\n",
    "docs_pymu_character = text_splitter_char.split_documents(docs_pymu)\n",
    "\n",
    "docs_py4llm_recursive = text_splitter_recur.split_documents(docs_py4llm)\n",
    "docs_py4llm_character = text_splitter_char.split_documents(docs_py4llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342f117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 43\n",
      "50 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(docs_pymu_recursive), len(docs_pymu_character))\n",
    "print(len(docs_py4llm_recursive), len(docs_py4llm_character))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d5309",
   "metadata": {},
   "source": [
    "## Convert Chunks to Embeddings and Store in FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40039605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize the HuggingFaceEmbeddings model\n",
    "\n",
    "# BGE example\n",
    "# model_name = \"BAAI/bge-base-en\"\n",
    "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# Create a FAISS vector store\n",
    "pymu_recur_vectorDB = FAISS.from_documents(documents=docs_pymu_recursive, embedding=embedding_model)\n",
    "pymu_char_vectorDB = FAISS.from_documents(documents=docs_pymu_character, embedding=embedding_model)\n",
    "\n",
    "py4llm_recur_vectorDB = FAISS.from_documents(documents=docs_py4llm_recursive, embedding=embedding_model)\n",
    "py4llm_char_vectorDB = FAISS.from_documents(documents=docs_py4llm_character, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9362e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "50\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(pymu_recur_vectorDB.index.ntotal)\n",
    "print(pymu_char_vectorDB.index.ntotal)\n",
    "print(py4llm_recur_vectorDB.index.ntotal)\n",
    "print(py4llm_char_vectorDB.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72ccf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 embedding norms: [1.00000001 0.99999995 1.00000003 1.00000006 0.99999997 1.00000004\n",
      " 1.00000005 1.00000001 1.00000003 1.00000001]\n",
      "All embeddings are normalized within tolerance.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Determine if embeddings are normalized\n",
    "embeddings = [embedding_model.embed_query(doc.page_content) for doc in docs_pymu_recursive]\n",
    "\n",
    "embeddings_array = np.array(embeddings)\n",
    "norms = np.linalg.norm(embeddings_array, axis=1)\n",
    "\n",
    "print(\"First 10 embedding norms:\", norms[:10])\n",
    "\n",
    "# Determine if embeddings are normalized\n",
    "if np.allclose(norms, 1.0, atol=1e-6):\n",
    "    print(\"All embeddings are normalized within tolerance.\")\n",
    "else:\n",
    "    print(\"Some embeddings are not normalized within tolerance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266abd1",
   "metadata": {},
   "source": [
    "## Persist Data in your Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bafd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymu_recur_vectorDB.save_local(\"../VectorDB/faiss_recur_index\")\n",
    "pymu_char_vectorDB.save_local(\"../VectorDB/faiss_char_index\")\n",
    "py4llm_char_vectorDB.save_local(\"../VectorDB/faiss4llm_char_index\")\n",
    "py4llm_recur_vectorDB.save_local(\"../VectorDB/faiss4llm_recur_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
